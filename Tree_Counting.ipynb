{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331f2ac0",
   "metadata": {},
   "source": [
    "## Tree Counting Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f201ead-842c-4d3f-9955-4e296c86fe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: D:\\7_Project\\palmtree_detection\n",
      "Updated directory: D:\\7_Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print (\"Current directory:\" , os.getcwd())\n",
    "os.chdir(\"..\")\n",
    "listDir = os.listdir()\n",
    "#Print the updated directory path\n",
    "oriPath = os.getcwd()\n",
    "print (\"Updated directory:\" , os.getcwd())\n",
    "os.chdir(\"palmtree_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb17bdf-844b-41d1-9810-edc59f31422f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\7_Project\\00_PKPS\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(oriPath, listDir[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c410a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_NAME = \"YPE_A_P19A1\"\n",
    "LADANG = 'IRAT'\n",
    "source = f'{os.path.join(oriPath, listDir[0])}/{LADANG}'#directory to a folder that contains image and prediction label.\n",
    "IMG_PATH = source+'/IMG/'#+IMG_NAME+\".tif\"\n",
    "MODEL = \"sdpr.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7265cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "['IRAT_1.tif', 'IRAT_10.tif', 'IRAT_11.tif', 'IRAT_12.tif', 'IRAT_2.tif', 'IRAT_3.tif', 'IRAT_4.tif', 'IRAT_5.tif', 'IRAT_6.tif', 'IRAT_7.tif', 'IRAT_8.tif', 'IRAT_9.tif']\n",
      "IRAT_1.tif\n",
      "Start prediction: 1 out of 12\n",
      "Performing prediction on 7921 slices.Elapsed time: 602.11 seconds\n",
      "IRAT_1\n",
      "\n",
      "Prediction time is: 548416.33 ms\n",
      "Prediction results are successfully exported to runs\\predict\\exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing inference on images:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                                                                     \n",
      "\n",
      "Performing inference on images:   0%|          | 0/1 [00:15<?, ?it/s]\n",
      "                                                                     \n",
      "\n",
      "Performing inference on images:   0%|          | 0/1 [09:20<?, ?it/s]\n",
      "Performing inference on images: 100%|##########| 1/1 [09:57<00:00, 597.29s/it]\n",
      "Performing inference on images: 100%|##########| 1/1 [09:57<00:00, 597.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA LOADED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2288\\1848301240.py:47: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 40000\n",
      "Height: 40000\n",
      "CONVERSION COMPLETE\n",
      "Error: Folder already exists at 'D:\\7_Project\\00_PKPS/IRAT/predict'.\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Destination path 'D:\\7_Project\\00_PKPS/IRAT/predict\\IRAT_1.txt' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 171\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m    170\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 171\u001b[0m print_tif_file_names(IMG_PATH)\n\u001b[0;32m    172\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    173\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 140\u001b[0m, in \u001b[0;36mprint_tif_file_names\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m    137\u001b[0m destination_path \u001b[38;5;241m=\u001b[39m folder_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mIMG_NAME\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    139\u001b[0m create_folder(folder_path)\n\u001b[1;32m--> 140\u001b[0m move_file(file_path, folder_path)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m#=========================================================================#\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m#  Delete previous prediction folder(exp)\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m#=========================================================================#\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 129\u001b[0m, in \u001b[0;36mprint_tif_file_names.<locals>.move_file\u001b[1;34m(source_path, destination_path)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmove_file\u001b[39m(source_path, destination_path):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;66;03m# Move the file from the source path to the destination path.\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mmove(source_path, destination_path)\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile moved successfully from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\shutil.py:884\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    881\u001b[0m     real_dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, _basename(src))\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(real_dst):\n\u001b[1;32m--> 884\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDestination path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m real_dst)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     os\u001b[38;5;241m.\u001b[39mrename(src, real_dst)\n",
      "\u001b[1;31mError\u001b[0m: Destination path 'D:\\7_Project\\00_PKPS/IRAT/predict\\IRAT_1.txt' already exists"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "def print_tif_file_names(folder_path):\n",
    "    print(\"start\")\n",
    "    import os\n",
    "    import time\n",
    "    import pickle\n",
    "    try:\n",
    "        # List all files in the folder.\n",
    "        files = os.listdir(folder_path)\n",
    "        print(files)\n",
    "\n",
    "        # Filter only the .tif files and print their names.\n",
    "        i=0\n",
    "        for file in files:\n",
    "            print(file)\n",
    "            if file.lower().endswith('.tif'):\n",
    "                i=i+1\n",
    "                print(\"Start prediction: \"+str(i)+\" out of \"+str(len(files)))\n",
    "                #=========================================================================#\n",
    "                #START PREDICTION\n",
    "                #=========================================================================#\n",
    "                start_time = time.time()\n",
    "                !sahi predict --slice_width 640 --slice_height 640 --overlap_height_ratio 0.3 --overlap_width_ratio 0.3 --model_confidence_threshold 0.40 --source {IMG_PATH}{file} --model_path sahi/{MODEL} --model_type yolov8 --export_pickle\n",
    "                end_time = time.time()\n",
    "                elapsed_time = end_time - start_time\n",
    "                print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "                #=========================================================================#                \n",
    "                #PICKLE TO YOLO                \n",
    "                #=========================================================================#\n",
    "                IMG_NAME = os.path.splitext(file)[0]\n",
    "                print(IMG_NAME)\n",
    "                dir_path = f'{oriPath}/palmtree_detection/runs/predict/exp/'\n",
    "                pickle_file = dir_path+'pickles/'+IMG_NAME+'.pickle'\n",
    "                # Load data from pickle file\n",
    "                with open(pickle_file, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                print(\"DATA LOADED\")\n",
    "                #=========================================================================#\n",
    "                #Image Size\n",
    "                #=========================================================================#\n",
    "                import imageio\n",
    "\n",
    "                def get_image_size(file_path):\n",
    "                    image = imageio.imread(file_path)\n",
    "                    image_width, image_height = image.shape[1], image.shape[0]\n",
    "                    return image_width, image_height\n",
    "\n",
    "                # Usage\n",
    "                image_width, image_height = get_image_size(IMG_PATH+file)\n",
    "                print(\"Width:\", image_width)\n",
    "                print(\"Height:\", image_height)\n",
    "                #=========================================================================#\n",
    "                #Converting Pickle to YOLO\n",
    "                #=========================================================================#\n",
    "                import re\n",
    "\n",
    "                def convert_bbox_to_yolo(bbox, image_width, image_height):\n",
    "                    x_min, y_min, x_max, y_max = bbox\n",
    "                    bbox_height = y_max - y_min\n",
    "                    bbox_width = x_max - x_min\n",
    "                    x_center = (x_max + x_min)/2.0\n",
    "                    y_center = (y_max + y_min)/2.0\n",
    "\n",
    "                    normalized_x = x_center / image_width\n",
    "                    normalized_y = y_center / image_height\n",
    "                    normalized_width = bbox_width / image_width\n",
    "                    normalized_height = bbox_height / image_height\n",
    "\n",
    "                    return normalized_x, normalized_y, normalized_width, normalized_height\n",
    "\n",
    "\n",
    "                def convert_pickle_to_yolo(pickle_data, image_width, image_height):\n",
    "                    bbox_info = re.search(r'bbox: BoundingBox: <\\((.*?), (.*?), (.*?), (.*?)\\)', pickle_data)\n",
    "                    class_id_info = re.search(r'category: Category: <id: (.*?),', pickle_data)\n",
    "                    pred_info = re.search(r'score: PredictionScore: <value: (.*?)>,', pickle_data)\n",
    "\n",
    "                    if bbox_info and class_id_info:\n",
    "                        bbox = tuple(map(float, bbox_info.groups()))\n",
    "                        class_id = int(class_id_info.group(1))\n",
    "                        pred_id = float(pred_info.group(1))\n",
    "\n",
    "                        yolo_data = convert_bbox_to_yolo(bbox, image_width, image_height)\n",
    "                        yolo_txt = f\"{class_id} {' '.join(map(str, yolo_data))} {pred_id}\"\n",
    "                        return yolo_txt\n",
    "                    else:\n",
    "                        return None\n",
    "\n",
    "                # Convert data to YOLO format\n",
    "                yolo_data = []\n",
    "                for item in data:\n",
    "                    yolo_txt = convert_pickle_to_yolo(str(item), image_width, image_height)\n",
    "                    if yolo_txt:\n",
    "                        yolo_data.append(yolo_txt)\n",
    "                # print(yolo_data)\n",
    "                #=========================================================================#\n",
    "                #Save YOLO text file\n",
    "                #=========================================================================#\n",
    "                # Save YOLO data to a text file\n",
    "                file_path=dir_path+IMG_NAME+'.txt'\n",
    "                with open(file_path, 'w') as f:\n",
    "                    for row in yolo_data:\n",
    "                        f.write(row + '\\n')\n",
    "\n",
    "                print(\"CONVERSION COMPLETE\")\n",
    "                \n",
    "                #=========================================================================#\n",
    "                #Move\n",
    "                #=========================================================================#\n",
    "                import shutil\n",
    "                import os\n",
    "\n",
    "                def create_folder(folder_path):\n",
    "                    try:\n",
    "                        # Create the folder at the specified path.\n",
    "                        os.mkdir(folder_path)\n",
    "                        print(f\"Folder created successfully at '{folder_path}'.\")\n",
    "                    except FileExistsError:\n",
    "                        print(f\"Error: Folder already exists at '{folder_path}'.\")\n",
    "\n",
    "                # Example usage:\n",
    "\n",
    "\n",
    "                def move_file(source_path, destination_path):\n",
    "                    try:\n",
    "                        # Move the file from the source path to the destination path.\n",
    "                        shutil.move(source_path, destination_path)\n",
    "                        print(f\"File moved successfully from '{source_path}' to '{destination_path}'.\")\n",
    "                    except FileNotFoundError:\n",
    "                        print(\"Error: Source file not found.\")\n",
    "                    except FileExistsError:\n",
    "                        print(f\"Error: A file already exists at '{destination_path}'.\")\n",
    "\n",
    "                folder_path = source+'/predict'\n",
    "                destination_path = folder_path+\"/\"+IMG_NAME+'.txt'\n",
    "\n",
    "                create_folder(folder_path)\n",
    "                move_file(file_path, folder_path)\n",
    "                \n",
    "                #=========================================================================#\n",
    "                #  Delete previous prediction folder(exp)\n",
    "                #=========================================================================#\n",
    "                \n",
    "                import shutil\n",
    "                def delete_folder(folder_path):\n",
    "                    try:\n",
    "                        # Delete the folder and its contents recursively.\n",
    "                        shutil.rmtree(folder_path)\n",
    "                        print(f\"Folder '{folder_path}' and its contents have been deleted.\")\n",
    "                    except FileNotFoundError:\n",
    "                        print(f\"Error: Folder '{folder_path}' not found.\")\n",
    "                    except PermissionError:\n",
    "                        print(f\"Error: Permission denied to delete folder '{folder_path}'.\")\n",
    "\n",
    "                # Example usage:\n",
    "                # folder_path = 'D:/7_Project/palmtree_detection/runs/predict/exp'\n",
    "\n",
    "                delete_folder(dir_path)                \n",
    "                #=========================================================================#\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Folder '{folder_path}' not found.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Error: Permission denied to access folder '{folder_path}'.\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "start_time = time.time()\n",
    "print_tif_file_names(IMG_PATH)\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time)/60\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} minutes\")\n",
    "print(\"PREDICITON FINISH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6004ada1",
   "metadata": {},
   "source": [
    "## Convert to Geopackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e5d1d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/20/2025 10:23:20 - INFO - numexpr.utils -   Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "03/20/2025 10:23:20 - INFO - numexpr.utils -   NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from adds.GenUtils import question, get_types, get_paths, make_folder, askPath, askFile, askInt, askFloat\n",
    "from adds.DLUtils import get_train_cfg, link_dataset, get_model_cfg, get_args\n",
    "from adds.inf2shp import det2gdf, copyfiles, get_world_file\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pyproj import CRS\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7710e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\7_Project\\palmtree_detection\n"
     ]
    }
   ],
   "source": [
    "home = os.getcwd()\n",
    "os.chdir(home)\n",
    "print(home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b7df25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory to a folder that contains image and prediction label.\n",
    "# LADANG = 'NYE'\n",
    "# source = \"D:/03_SDPR_TREE_COUNT/\"+LADANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c27ec8e0-e964-4331-b20e-1791c644008b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "haluu\n",
      "Please enter only: \n",
      "yes, y, no, n\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m     geoshapes \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(pd\u001b[38;5;241m.\u001b[39mconcat([geoshapes, geo], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), crs\u001b[38;5;241m=\u001b[39minit_crs)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Rest of your code remains the same\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m fname \u001b[38;5;241m=\u001b[39m make_folder(source, LADANG)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfname: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m fname)\n\u001b[0;32m     35\u001b[0m geoshapes\u001b[38;5;241m.\u001b[39mto_file(fname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m LADANG \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gpkg\u001b[39m\u001b[38;5;124m'\u001b[39m, driver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPKG\u001b[39m\u001b[38;5;124m'\u001b[39m, crs\u001b[38;5;241m=\u001b[39minit_crs, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\7_Project\\palmtree_detection\\adds\\GenUtils.py:31\u001b[0m, in \u001b[0;36mmake_folder\u001b[1;34m(path, name)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(folder):\n\u001b[0;32m     30\u001b[0m        qst \u001b[38;5;241m=\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Folder exist, remove it? \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 31\u001b[0m        answ \u001b[38;5;241m=\u001b[39m question(qst,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     32\u001b[0m        \u001b[38;5;28;01mif\u001b[39;00m answ \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     33\u001b[0m            shutil\u001b[38;5;241m.\u001b[39mrmtree(folder)\n",
      "File \u001b[1;32mD:\\7_Project\\palmtree_detection\\adds\\GenUtils.py:23\u001b[0m, in \u001b[0;36mquestion\u001b[1;34m(question, answers)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease enter only: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m*\u001b[39manswers, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m     answ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mquestion\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  Answer: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(answ)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "from shapely.geometry import Point, Polygon\n",
    "from pyproj import CRS\n",
    "import fiona\n",
    "\n",
    "DST_CRS= CRS.from_wkt('PROJCRS[\\\"Equirectangular MARS\\\",BASEGEOGCRS[\\\"GCS_MARS\\\",DATUM[\\\"unnamed\\\",ELLIPSOID[\\\"unnamed\\\",3396036.8126024,0,LENGTHUNIT[\\\"metre\\\",1,ID[\\\"EPSG\\\",9001]]]],PRIMEM[\\\"Reference meridian\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433,ID[\\\"EPSG\\\",9122]]]],CONVERSION[\\\"unnamed\\\",METHOD[\\\"Equidistant Cylindrical (Spherical)\\\",ID[\\\"EPSG\\\",1029]],PARAMETER[\\\"Latitude of 1st standard parallel\\\",-5,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8823]],PARAMETER[\\\"Longitude of natural origin\\\",180,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8802]],PARAMETER[\\\"False easting\\\",0,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8806]],PARAMETER[\\\"False northing\\\",0,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8807]]],CS[Cartesian,2],AXIS[\\\"easting\\\",east,ORDER[1],LENGTHUNIT[\\\"metre\\\",1,ID[\\\"EPSG\\\",9001]]],AXIS[\\\"northing\\\",north,ORDER[2],LENGTHUNIT[\\\"metre\\\",1,ID[\\\"EPSG\\\",9001]]]]')\n",
    "# print(\"test:\"+source)\n",
    "print(\"TEST\")\n",
    "detections = get_paths(source+'/predict/', 'txt')\n",
    "detections_paths = [source+'/predict/'+file for file in detections]\n",
    "# print(detections_paths)\n",
    "\n",
    "geodataframes = det2gdf(detections_paths, 'tif', IMG_PATH)\n",
    "\n",
    "# Initialize geoshapes with the first GeoDataFrame\n",
    "geoshapes = geodataframes[0].copy()  # Use copy() to avoid modifying the original\n",
    "\n",
    "# Set the initial CRS\n",
    "init_crs = geoshapes.crs\n",
    "\n",
    "# Iterate over the rest of the GeoDataFrames\n",
    "for geo in geodataframes[1:]:\n",
    "    # Transform to the common CRS if necessary\n",
    "    if geo.crs != init_crs:\n",
    "        geo = geo.to_crs(init_crs)\n",
    "    \n",
    "    # Concatenate the GeoDataFrames\n",
    "    geoshapes = gpd.GeoDataFrame(pd.concat([geoshapes, geo], ignore_index=True), crs=init_crs)\n",
    "\n",
    "# Rest of your code remains the same\n",
    "fname = make_folder(source, LADANG)\n",
    "\n",
    "print('fname: ' + fname)\n",
    "geoshapes.to_file(fname + '/' + LADANG + '.gpkg', driver='GPKG', crs=init_crs, engine='fiona')\n",
    "\n",
    "source_path = source + '/' + LADANG\n",
    "destination_path = source + '/GPKJ'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "print('AFIQ HENSEM.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae08b64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "# from shapely.geometry import Point, Polygon\n",
    "# from pyproj import CRS\n",
    "# import fiona\n",
    "\n",
    "# DST_CRS= CRS.from_wkt('PROJCRS[\\\"Equirectangular MARS\\\",BASEGEOGCRS[\\\"GCS_MARS\\\",DATUM[\\\"unnamed\\\",ELLIPSOID[\\\"unnamed\\\",3396036.8126024,0,LENGTHUNIT[\\\"metre\\\",1,ID[\\\"EPSG\\\",9001]]]],PRIMEM[\\\"Reference meridian\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433,ID[\\\"EPSG\\\",9122]]]],CONVERSION[\\\"unnamed\\\",METHOD[\\\"Equidistant Cylindrical (Spherical)\\\",ID[\\\"EPSG\\\",1029]],PARAMETER[\\\"Latitude of 1st standard parallel\\\",-5,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8823]],PARAMETER[\\\"Longitude of natural origin\\\",180,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8802]],PARAMETER[\\\"False easting\\\",0,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8806]],PARAMETER[\\\"False northing\\\",0,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8807]]],CS[Cartesian,2],AXIS[\\\"easting\\\",east,ORDER[1],LENGTHUNIT[\\\"metre\\\",1,ID[\\\"EPSG\\\",9001]]],AXIS[\\\"northing\\\",north,ORDER[2],LENGTHUNIT[\\\"metre\\\",1,ID[\\\"EPSG\\\",9001]]]]')\n",
    "# # print(\"test:\"+source)\n",
    "# detections = get_paths(source+'/predict/', 'txt')\n",
    "# detections_paths = [source+'/predict/'+file for file in detections]\n",
    "# # print(detections_paths)\n",
    "# geodataframes = det2gdf(detections_paths, 'tif', IMG_PATH)\n",
    "\n",
    "# try:\n",
    "#     geoshapes.crs\n",
    "# except:\n",
    "#     geoshapes = geodataframes[0]\n",
    "    \n",
    "# init_crs = geodataframes[0].crs\n",
    "# for geo in geodataframes:\n",
    "#     if geo.crs != init_crs:\n",
    "#         geo = geo.to_crs(init_crs)\n",
    "# #    geoshapes.append(geo, ingore_index=True)\n",
    "#     geoshapes = gpd.GeoDataFrame(pd.concat([geoshapes,geo],ignore_index=True),crs=init_crs)\n",
    "\n",
    "# fname = make_folder(source,LADANG)\n",
    "\n",
    "# print('fname: '+fname)\n",
    "# geoshapes.to_file(fname+'/'+LADANG+'.gpkg', driver='GPKG', crs=init_crs, engine='fiona') \n",
    "# # geoshapes.to_file(fname+'/Inferred_landforms.shp', mode=\"a\", crs=init_crs)\n",
    "\n",
    "# source_path = source+'/'+LADANG\n",
    "# destination_path = source+'/GPKJ'\n",
    "# shutil.move(source_path, destination_path)\n",
    "\n",
    "# print('AFIQ HENSEM.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a9a97-aa9b-4196-b1d4-060cf8e3dcab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
